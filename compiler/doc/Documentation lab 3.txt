For lab 3/C I (tried) implementing a x86-64 backend with register allocation optimization


As for the x86 extension:
I'm still failing some tests (fails 7/36 good tests), they either print the wrong thing, or they never "halt".
I'll make sure to fix this until the final deadline

These are the tests that fail:
    core001     no halt
    core012     prints nothing
    core013     prints nothing
    core017     no halt
    core019     no halt
    core029     no halt
    intarith5   prints nothing

Some known issues:
    i push all registers manually before calling a function, it makes the code slow and ugly.

So running the docker like normal won't work since it will get stuck on some tests.
If you want to try some tests, you can open jlc.hs and look in the main do-block on line 20:
    the default input lets you run that given test in the docker, the one used right now is intarith5.jl
        it fails, since it prints nothing
    the second input option can be used when running jlc.hs outside the docker (you have to change the path on your computer)
    the third option can be used to verify that the register allocation optimization works (more on that below)
    the fourth option is used to test the docker like normal, there's no point in using it now, as mentioned.


The register allocation works correctly, which can be verified by using src/10.jl as input.
10.jl has many local variables so you can see that they first get allocated to "real" registers,
and then to the stack when a register has to spill, for both ints and doubles. 
The register allocation is very slow however, on my computer it can take 10 seconds to compile 10.jl.
I probably need to use some different data structures;
I use bitarrays to represent the def-, use-, succsessor- and livein-sets, and this becomes a bit problematic for
the successor set for example; There can be 200+ lines of code, each line has a successor set 200 elements.
So just from this we get 40 000 elements.





---------- x86Backend.hs structure:
The structure is the same as the LLVM backend, apart from the new register optimization section.
But I'll include a copy of the description of the borrowed LLVM backend structure at the bottom of this document. 
Ill also include any relevant changes in each section from the last backend.

X86Backend.hs compiles the x86 code. it has 6 main sections: 
entry point
types + state
functions for interacting with the state
functions for converting code to "x86 strings"
functions for saving (emitting) code to the state
helper functions for bit arrays ------------------------------ new
register allocation functions   ------------------------------ new
functions for compiling functions
functions for compiling statements
functions for compiling expressions





---------------------- helper functions for bit arrays: ------------
simple functions for creating bit arrays and performing operations like bitwise or




--------------------- register allocation functions --------------------
We first have the "main" function for register allocation that combines all sub-steps of the "algorithm".
The main function itself is called inside the compileFun function after compiling each function.

This is how the register allocation works on an abstract level:
First we generate the code without register allocation and use new temporary registers for every calculcation.
Then we run the register allocation optimization and swap the temporary registers with real registers or a "stack location" if we spill the register.
We also have to do "sub RSP, 8*x" where x is the number of variables we spill 
Furthermore, we have to 128 bit align the stack (by pushing and popping RCX) if x is odd.

The details of the register allocation follows the algorithm presented in the lectures.
The only interesting detail would be how we spill registers;
    When we look for a "node / register" to remove from the interference graph, 
    we keep track of the degree for each node, so if we dont find a node with degree < k 
    to allocate a register to, we spill the node with the highest degree.
    













---------------------- entry point:
the compile function compiles all functions, it appends imports, 
strings constants and the functions themselves







---------------------- types + state:
we use a state monad that contains variable / register enums, 
compiled code and function / variable signatures.
We also have a "Code" data type that contains all relevant x86 instruction templates.


--------- Changes:

We added a Parameter type, which is used to distinguish temporary registers that need to be "register-allocated"
and parameters, that dont need to change.
We added a "value-data-type" "X86" that can be concrete registers like RAX, stack variables, parameters and local variables.
These are the data values we get after performing register allocation optimization.
We added "output-code" types for x86 rather than x86.






---------------------- functions for interacting with the state:
we have methods for getting / fetching the "previous value". This lets use
use the result from an instruction in the next one. We also have functions for 
adding / getting variables, registers and labels.

--------- Changes:
We updated the "loadReg" function to load values to RAX or XMM0 so that we avoid illegal operations like "add [RSP + 8], [RSP + 16]"






---------------------- functions for converting code to "x86 strings":
these functions convert our "x86 instruction templates" to strings

---------------------- functions for saving (emitting) code to the state:
these functions take an x86 instruction template, turns it into a string and 
puts it in the state.

---------------------- functions for compiling functions:
given a function, we compile its header and its statements.
I'm a little unsatisfied with the use of "params" in the state and the
helper function compileFun. Ideally you would merge compileFun and 
compileDef to avoid needing the "params" variable in the state.
The reason why it is this way is because I couldnt figure out how to
perform execState / runState in such a way that I could return params
from compileFun.



----------- Changes:
We reset "next register" and "next parameter" for each function, since you dont need to worry about conflicting names.
At the start and end of each function we save, respectively restore RBP.
As mentioned, we perform the register allocation optimization at the end of the compileDun function.










---------------------- functions for compiling statements:
given a statement, we compile it by emitting x86 instructions directly or 
by calling the compileExp function. The compileStm function returns a bool
that tells us if the statement guarantees a return. If it does, then we can
omit the following statements, as mentioned before.



--------- Changes:
We made a function "fixReturnReg" that moves the result to RAX / XMM0 when compiling return statements.







---------------------- functions for compiling expressions:
The compileExp function compiles expressions to x86 code. The function takes
a bool argument that tells us if the expression is used as an operand or 
argument for a different expression. If so, then we make sure that it is 
not overridden by subsequent "arguments" by passing this bool to the
setPrevVal function. This makes it so that we append the argument to the end
of the list, rather than ovverriding the last element.



-------- Changes:
we use a function "defaultReg" that simply gives RAX, RBX, XMM0 and XMM1 as standard for binary operations.
for binary operations:
    We first compile the the first argument and mov it to a temporary register to prevent 
    the second argument from overriding it.
    We then move the second argument away from RAX/XMM0 if its there so we can place the first argument there.
    then we "print" the instruction
We always "mov" literals (like 3.456 and 7) to a temporary register to avoid trouble with instructions that cant handle literals
    its probably better to instead only "mov" if it's 100% necassary to make the code less bloated.
when compiling function calls (EApp expressions): 
    push and pop registers the caller is responsible for.
    Right now we push and pop all "caller" registers even if we dont use them, which creates a lot of spaghetti code,
    I hope to fix this next week.
    if we're calling an extern function from the runtime we:
        we push the argument to RDI
    if we are calling a function defined inside the program:
        we push and pop RCX to align the stack if theres an odd number of arguments 
        we push int arguments to the stack using "push"
        we push double arguments to the stack using 
            sub rsp 8
            mov [RSP], arg